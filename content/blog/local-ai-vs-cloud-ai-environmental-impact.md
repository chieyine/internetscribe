---
title: "Local AI vs. Cloud AI: The Environmental Impact"
date: "2024-06-21"
description: "Training and running massive AI models in the cloud consumes vast amounts of energy. Is local AI greener?"
---

Data centers currently consume about 1-2% of global electricity. As AI grows, this is skyrocketing.

## The Cost of a Query

Every time you ask ChatGPT a question or send audio to a cloud API, a massive GPU cluster spins up in a data center, consuming electricity and water (for cooling).

## Distributed Compute

**InternetScribe** uses the device you already have turned on. Your laptop is already running. Using its idle CPU/GPU cycles to transcribe audio is far more energy-efficient than transmitting data across the world to a power-hungry data center.

Be green. Compute locally.
